---
title: "GVAR - Model Fitting and Results"
output:
  html_document:
    toc: yes
    toc_float: yes
    collapsed: no
    smooth_scroll: yes
---

```{r setup, include = FALSE}
# Libraries
packages <- c(
  "tidyverse",
  "devtools",
  "readxl",
  "lubridate",
  "rmarkdown",
  "psych",
  "cmdstanr",
  "loo",
  "bayesplot",
  "posterior",
  "bayestestR",
  "here",
  "rtf",
  "sjlabelled",
  "tsnet",
  "BGGM",
  "graphicalVAR",
  "mvtnorm"
)
#remotes::install_github("donaldRwilliams/BGGM")
#devtools::install_github("bsiepe/tsnet")
if (!require("pacman")) install.packages("pacman")
pacman::p_load(packages, update = F, character.only = T)

set.seed(35037)
```

### Simulate data
```{r}
gvar_mod <- graphicalVAR::randomGVARmodel(Nvar = 8,
                              probKappaEdge = .3,
                              probBetaEdge = .2)
# DGP matrices
gvar_mod$beta     # regression weights
gvar_mod$kappa    # precision matrix

# Simulate data from it
gvar_dat <- graphicalVAR::graphicalVARsim(nTime = 200, 
                                          beta = gvar_mod$beta,
                                          kappa = gvar_mod$kappa)

# Additionally, use data from our preprint
l_graphs <- readRDS(here("data", "l_graphs.rds"))

# Choose graph 6
gvar_mod <- l_graphs$graph6

# Add partial correlations
gvar_mod$PCC <- -cov2cor(gvar_mod$kappa)
diag(gvar_mod$PCC) <- 0

# Simulate data
gvar_dat <- graphicalVAR::graphicalVARsim(nTime = 200, 
                                          beta = gvar_mod$beta,
                                          kappa = gvar_mod$kappa)


```

Scale data
```{r}
Y <- gvar_dat %>% apply(., 2, scale)
K <- ncol(gvar_dat)
n_t <- nrow(gvar_dat)
```

### Specify Priors
```{r}
# prior on the locations of partial correlations (scaled Beta location)
prior_Rho_loc <- matrix(.5, nrow = K, ncol = K)
# prior_Rho_scale <- matrix(sqrt(.5), nrow = K, ncol = K) # sqrt(mu) corresponds to uniform distribution
prior_Rho_scale <- matrix(.4, nrow = K, ncol = K) # bit more regularization

prior_Beta_loc <- matrix(0, nrow = K, ncol = K)
prior_Beta_scale <- matrix(.5, nrow = K, ncol = K)  # regularize a bit
```

#### Plot prior choices for scaled beta
BS: Would be good to not make this uniform, high partial correlations are quite unrealistic.
Would decrease the prior sd for the partial correlations
```{r}
mu <- .5
sd <- .4
a <- mu / (sd * sd)
b <- (1-mu) / (sd * sd)
hist((rbeta(1e6,a, b) - .5) * 2)
```

## Fit VAR Model in Stan
```{r stan data & compilation}
# prepare stan data
stan_data <-
  list(K = K,
       "T" = n_t,
       Y = as.matrix(Y),
       prior_Rho_loc = prior_Rho_loc,
       prior_Rho_scale = prior_Rho_scale,
       prior_Beta_loc = prior_Beta_loc,
       prior_Beta_scale = prior_Beta_scale
       )
# Choose model to fit
model_name <- "VAR_loglik"
# number of MCMC chains
n_chains <- 4
```

```{r sampling, message=FALSE, eval=FALSE}
# Compile model
var_lkj_model <- cmdstanr::cmdstan_model(
  stan_file = here("scripts", paste0(model_name, ".stan")),
  pedantic = TRUE#,   
  #quiet = FALSE
  )
# Run sampler
var_lkj_fit <- var_lkj_model$sample(
  data = stan_data,
  seed = 2023,
  chains = n_chains,
  parallel_chains = n_chains,
  iter_warmup = 500,
  iter_sampling = 500,
  refresh = 500,
  thin = 1,
  adapt_delta = .8,
  init = .1
)
# time to fit
var_lkj_fit$time()$total
```

```{r}
# Compile model
var_lkj_model <- rstan::stan_model(
  file = here("scripts", paste0(model_name, ".stan")))
# Run sampler
var_lkj_fit <- rstan::sampling(
  object = var_lkj_model,
  data = stan_data,
  seed = 2023,
  chains = n_chains,
  cores = n_chains,
  iter = 1000,
  warmup = 500,
  refresh = 500,
  thin = 1,
  init = .1,
  control = list(adapt_delta = .8)
)
```

## Effective sample size (ESS) & Rhat Plots
```{r}
# color scheme
color_scheme_set(scheme = "purple")
# Effective sample sizes
plot_neff <-
  mcmc_neff_hist(bayesplot::neff_ratio(var_lkj_fit), binwidth = .01) +
  labs(title = "A") +
  guides(color = "none", fill = "none") +
  theme(
    legend.text = element_blank(),
    legend.key = element_blank(),
    title = element_text(size = 16, face = "bold")
  )
# Rhat
# BS: Why does this have missings?
plot_rhat <-
  bayesplot::mcmc_rhat_hist(bayesplot::rhat(var_lkj_fit)) +
  labs(title = "B") +
  guides(color = "none", fill = "none") +
  theme(
    legend.text = element_blank(),
    legend.key = element_blank(),
    title = element_text(size = 16, face = "bold")
  ) +
  yaxis_text(on = TRUE)
# Combined plot
plot_diagnostics <- gridExtra::grid.arrange(plot_neff, plot_rhat, ncol = 2)
```

### LOO
```{r}
var_lkj_loo <- var_lkj_fit$loo()
print(var_lkj_loo)
plot(var_lkj_loo)
```

```{r}
#param_ests <- var_lkj_fit$summary(c("B", "Rho","mu_B","sigma_B", "sigma_theta"))
param_ests <- var_lkj_fit$summary()
```

# Parameter Recovery

### Betas
```{r}
medians_beta <-
  var_lkj_fit$summary("Beta") %>% 
  dplyr::select(median) %>% 
  unlist() %>% 
  round(2) %>% 
  matrix(., nrow = K, byrow = FALSE)
cor.plot(medians_beta)

cor.plot(gvar_mod$beta)
```

### Difference in Betas
```{r}
diff_Rho <- medians_beta - gvar_mod$beta
cor.plot(diff_Rho)
```

```{r}
draws_beta <- var_lkj_fit$draws("Beta") %>% as_draws_matrix()
bayesplot::ppc_intervals(gvar_mod$beta %>% as.vector(),draws_beta)
```

### Partial Correlations
```{r}
medians_rho <-
  var_lkj_fit$summary("Rho") %>% 
  dplyr::select(median) %>% 
  unlist() %>% 
  round(2) %>% 
  matrix(., nrow = K, byrow = FALSE)
cor.plot(medians_rho)

cor.plot(gvar_mod$PCC)

```

### Difference in partial correlations
```{r}
diff_Rho <- medians_rho - gvar_mod$PCC
cor.plot(diff_Rho)
```


```{r}
draws_rho <- var_lkj_fit$draws("Rho") %>% as_draws_matrix()
bayesplot::ppc_intervals(gvar_mod$PCC %>% as.vector(),draws_rho)
```

***

# Loglik extraction
```{r}
source(here("scripts","functions.R"))
draws_sigma <- var_lkj_fit$draws("Sigma") %>% as_draws_matrix()

log_lik_0 <-
  log_lik_gVAR(Y = Y,
               draws_beta = draws_beta,
               draws_sigma = draws_sigma, 
               n_cores = 4)

chain_ids <- var_lkj_fit$draws("Beta") %>% 
  as_draws_df() %>% 
  select(.chain) %>% unlist()

loo_0 <- loo(log_lik_0, r_eff = relative_eff(log_lik_0, chain_ids)
)

```


# Posterior comparisons

Compare data structures of BGGM and the stan model/posterior package
```{r}
# Load data of two individuals
data <- BGGM::ifit
data_1 <- subset(data, id == 1)
data_3 <- subset(data, id == 3)

# Estimate networks
# (should perform detrending etc. in a real use case)
net_1_bggm <- BGGM::var_estimate(data_1[,-1],
                            rho_sd = 0.25, 
                            Beta_sd = 0.5,
                            iter = 50000)
net_3_bggm <- BGGM::var_estimate(data_3[,-1],
                            rho_sd = 0.25, 
                            Beta_sd = 0.5,
                            iter = 50000)

```

### Specify Priors
```{r}
Y_1 <- data_1[,-1] %>% apply(., 2, scale)
K <- ncol(Y_1)
n_t <- nrow(Y_1)
prior_Rho_loc <- matrix(.5, nrow = K, ncol = K)
prior_Rho_scale <- matrix(.4, nrow = K, ncol = K)
prior_Beta_loc <- matrix(0, nrow = K, ncol = K)
prior_Beta_scale <- matrix(.5, nrow = K, ncol = K)  # regularize a bit

priors <- list(
  prior_Rho_loc = prior_Rho_loc,
  prior_Rho_scale = prior_Rho_scale,
  prior_Beta_loc =  prior_Beta_loc,
  prior_Beta_scale = prior_Beta_scale
)

net_1_stan <- fit_gVAR_stan(data = Y_1, priors = priors)


Y_3 <- data_3[,-1] %>% apply(., 2, scale)
K <- ncol(Y_3)
n_t <- nrow(Y_3)
prior_Rho_loc <- matrix(.5, nrow = K, ncol = K)
prior_Rho_scale <- matrix(.4, nrow = K, ncol = K)
prior_Beta_loc <- matrix(0, nrow = K, ncol = K)
prior_Beta_scale <- matrix(.5, nrow = K, ncol = K)  # regularize a bit

net_1_stan <- fit_gVAR_stan(data = Y_3, priors = priors)
```

Posterior samples are in a slightly different format when we use the BGGM package
in BGGM, they are in a tensor format. I think this will be the most efficient format for the test.

```{r}
net_1$fit$beta
draws_beta %>% View()

```

```{r}
tsnet::
```


### Compare Models for same True Parameters
```{r}
gvar_mod <- graphicalVAR::randomGVARmodel(Nvar = 8,
                              probKappaEdge = .3,
                              probBetaEdge = .2)

data_1 <- gvar_dat <- graphicalVAR::graphicalVARsim(nTime = 200,
                                                    beta = gvar_mod$beta,
                                                    kappa = gvar_mod$kappa)

data_2 <- gvar_dat <- graphicalVAR::graphicalVARsim(nTime = 200,
                                                    beta = gvar_mod$beta,
                                                    kappa = gvar_mod$kappa)
K <- ncol(data_1)
prior_Rho_loc <- matrix(.5, nrow = K, ncol = K)
prior_Rho_scale <- matrix(.4, nrow = K, ncol = K)
prior_Beta_loc <- matrix(0, nrow = K, ncol = K)
prior_Beta_scale <- matrix(.5, nrow = K, ncol = K)  # regularize a bit

source(here("scripts", "functions.R"))
priors <- list(
  prior_Rho_loc = prior_Rho_loc,
  prior_Rho_scale = prior_Rho_scale,
  prior_Beta_loc =  prior_Beta_loc,
  prior_Beta_scale = prior_Beta_scale
)
```

```{r message=FALSE}
net_1_fit <- fit_gVAR_stan(data = data_1, priors = priors)
net_2_fit <- fit_gVAR_stan(data = data_2, priors = priors)
```

```{r}
source(here("scripts","functions.R"))

cores <- parallel::detectCores()-4
net_1_data_1_loo <- loo_gVAR(stan_fit = net_1_fit, data = data_1, n_cores = cores)
net_1_data_2_loo <- loo_gVAR(stan_fit = net_1_fit, data = data_2, n_cores = cores)
net_2_data_2_loo <- loo_gVAR(stan_fit = net_2_fit, data = data_2, n_cores = cores)
net_2_data_1_loo <- loo_gVAR(stan_fit = net_2_fit, data = data_1, n_cores = cores)
```

```{r}
plot(net_1_data_1_loo)
plot(net_1_data_2_loo)
plot(net_2_data_2_loo)
plot(net_2_data_1_loo)
```

```{r}
loo_compare(net_1_data_1_loo, net_1_data_2_loo)
loo_compare(net_2_data_2_loo, net_2_data_1_loo)
```


```{r}
net_1_data_1_logml <- bridgesampling::bridge_sampler(
  samples = net_1_fit,
  stan_fit = net_1_fit
)$logml

net_1_data_2_logml <- bridgesampling::bridge_sampler(
  samples = net_1_fit,
  stan_fit = net_1_fit,
  log_posterior = log_lik_gVAR,
  data = data_2
)$logml

net_2_data_2_logml <- bridgesampling::bridge_sampler(
  samples = net_2_fit,
  stan_fit = net_2_fit
)$logml

net_2_data_1_logml <- bridgesampling::bridge_sampler(
  samples = net_2_fit,
  stan_fit = net_2_fit,
  log_posterior = log_lik_gVAR,
  data = data_1
)$logml

```

```{r}
bridgesampling::bayes_factor(net_1_data_1_logml, net_1_data_2_logml)
bridgesampling::bayes_factor(net_2_data_2_logml, net_2_data_1_logml)
```


```{r}
(net_1_data_1_loo$elpd - net_1_data_1_logml) - (net_1_data_2_loo$elpd - net_1_data_2_logml) 
```


```{r}
var_lkj_draws <- rstan::extract(var_lkj_fit)
var_lkj_LML <- bridgesampling::bridge_sampler(
  samples = var_lkj_fit,
  stan_fit = var_lkj_fit,
  method = "warp3"
)
bridgesampling::logml(var_lkj_LML)
var_lkj_LML$logml
```




# Compare Variational Inference
```{r}
# Compile model
var_lkj_model <- cmdstanr::cmdstan_model(
  stan_file = here("scripts", paste0(model_name, ".stan")),
  pedantic = TRUE#,   
  #quiet = FALSE
  )
# Run variational
var_lkj_fit_vb <- var_lkj_model$variational(
  algorithm = "fullrank",
  data = stan_data,
  seed = 2023,
  tol_rel_obj = .001,
  init = .1,
  refresh = 1000
)
# time to fit
var_lkj_fit_vb$time()$total
```

```{r}
medians_Beta_vb <-
  var_lkj_fit_vb$summary("Beta") %>% 
  dplyr::select(median) %>% 
  unlist() %>% 
  round(2)
plot(medians_Beta_vb, medians_beta %>% as.vector())
abline(coef = c(0,1))
```


```{r}
medians_rho_vb <-
  var_lkj_fit_vb$summary("Rho") %>% 
  dplyr::select(median) %>% 
  unlist() %>% 
  round(2)

# This looks abit more ugly now!
plot(medians_rho_vb, medians_rho %>% as.vector())
abline(coef = c(0,1))
```

```{r}
draws_Beta_vb <- var_lkj_fit_vb$draws("Beta") %>% as_draws_matrix()
bayesplot::ppc_intervals(gvar_mod$beta %>% as.vector(),draws_beta)+
    ylim(c(-1,1))
bayesplot::ppc_intervals(gvar_mod$beta %>% as.vector(),draws_Beta_vb)+
    ylim(c(-1,1))
```

```{r}
draws_rho_vb <- var_lkj_fit_vb$draws("Rho") %>% as_draws_matrix()
bayesplot::ppc_intervals(gvar_mod$PCC %>% as.vector(),draws_rho)+
  ylim(c(-.7,.7))
bayesplot::ppc_intervals(gvar_mod$PCC %>% as.vector(),draws_rho_vb)+
    ylim(c(-.7,.7))
```

***



